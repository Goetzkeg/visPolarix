{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization - Interactive reconstructions\n",
    "\n",
    "This notebook loads previously trained models and allows for reconstructions interactively.\n",
    "By manual choice of individual parameters of dimensions in $\\boldsymbol{z} \\in \\mathbb{R}^d$ the user can specify the properties of the sample to be reconstructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the background color of the widget. Only needed for something that is not white\n",
    "color_bg = '#282828'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This mode allows for more fluent updates\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from attrdict import AttrDict\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from ipywidgets import interactive, fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_after_con2D(dim_in = (640,2360), padding = [0,0], dilation=[1,1], kernel_size=[5,5],stride =[1,1]):\n",
    "    if type(padding) == int:  padding = [padding,padding]\n",
    "    if type(dilation) == int:  dilation = [dilation,dilation]\n",
    "    if type(kernel_size) == int:  kernel_size = [kernel_size,kernel_size]\n",
    "    if type(stride) == int:  stride = [stride,stride]\n",
    "    \n",
    "    if padding == 'same':\n",
    "        assert stride == 1, 'padding = same only valid for strides = 1'\n",
    "        padding = [np.floor(kernel_size[0]/2.0), np.floor(kernel_size[1]/2.0)]\n",
    "        \n",
    "    dim0 = int((dim_in[0] + 2*padding[0] - dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
    "    dim1 = int((dim_in[1] + 2*padding[1] - dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
    "    return (dim0,dim1)\n",
    "\n",
    "\n",
    "def get_size_after_pooling2D(dim_in = (640,2360), padding = [0,0], dilation=[1,1], kernel_size=[5,5],stride =[1,1]):\n",
    "    \n",
    "    if padding == 'same':\n",
    "        assert stride in [1,[1,1]], 'padding = same only valid for strides = 1'\n",
    "        padding = [np.floor(kernel_size[0]/2.0), np.floor(kernel_size[1]/2.0)]\n",
    "    \n",
    "    if type(padding) == int:  padding = [padding,padding]\n",
    "    if type(dilation) == int:  dilation = [dilation,dilation]\n",
    "    if type(kernel_size) == int:  kernel_size = [kernel_size,kernel_size]\n",
    "    if type(stride) == int:  stride = [stride,stride]\n",
    "        \n",
    "    \n",
    "    \n",
    "    dim0 = int((dim_in[0] + 2*padding[0] - dilation[0]*(kernel_size[0]-1)-1)/stride[0] +1)\n",
    "    dim1 = int((dim_in[1] + 2*padding[1] - dilation[1]*(kernel_size[1]-1)-1)/stride[1] +1)\n",
    "    \n",
    "    return (dim0,dim1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Conv2d_encoder(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_dim= (640,2360), \n",
    "                 train = True,\n",
    "                 device = 'cpu',\n",
    "                 activations='mish', \n",
    "                 conv_sizes_encoder = [5,5,5], \n",
    "                 conv_nr_encoder = [1,8,16,32], \n",
    "                 conv_strides_encoder = 1,\n",
    "                 pooling_kernel_size = [3,3,3],\n",
    "                 pooling_stride = [3,3,3],             \n",
    "                 ful_cn_nodes_encoder = [-1,500,24],\n",
    "                 dropout_encoder = -1,\n",
    "                 batch_norm = False):\n",
    "                 \n",
    "        super().__init__()\n",
    "        self.latent_dims = int(ful_cn_nodes_encoder[-1]/2.)\n",
    "\n",
    "        ## all this is to determine the dimension after all convolutional and pooling layers     \n",
    "        dim = input_dim\n",
    "        padding = 0# 'same' not supported by decoder\n",
    "        self.pooling_dims = []\n",
    "        self.conv_dims = [] #they are needed for transpose convs\n",
    "        \n",
    "        if type(conv_strides_encoder) == int:\n",
    "            conv_strides_encoder = [conv_strides_encoder for _ in conv_sizes_encoder]\n",
    "        \n",
    "        padding = 0\n",
    "        for i in range(len(conv_sizes_encoder)):\n",
    "            self.conv_dims.append([dim[0],dim[1]])\n",
    "            dim = get_size_after_con2D(\n",
    "                dim_in = dim,\n",
    "                padding = padding,\n",
    "                kernel_size = conv_sizes_encoder[i],\n",
    "                stride = conv_strides_encoder[i],\n",
    "                )\n",
    "            if len(pooling_kernel_size) >0:\n",
    "                self.pooling_dims.append([dim[0],dim[1]])\n",
    "                dim = get_size_after_pooling2D(\n",
    "                    dim_in = dim,\n",
    "                    padding =0,\n",
    "                    kernel_size = pooling_kernel_size[i],\n",
    "                    stride = pooling_stride[i],\n",
    "                    )\n",
    "                    \n",
    "        self.last_dim = dim     \n",
    "        ##now we have our dim.\n",
    "        \n",
    "\n",
    "class Conv2d_decoder(nn.Module):\n",
    "    \n",
    "     def __init__(self, \n",
    "                 last_dim, #2d\n",
    "                 activations='mish', \n",
    "                 conv_sizes_decoder = [5,5,5], \n",
    "                 conv_nr_decoder = [1,8,16,32], \n",
    "                 conv_strides_decoder = 1,          \n",
    "                 pooling_dims = [3,3,3],\n",
    "                 conv_dims = [3,3,3],\n",
    "                 pooling_mode = 'nearest',\n",
    "                 ful_cn_nodes_decoder = [-1,500,24],\n",
    "                 dropout_decoder = -1,\n",
    "                 conv_type = 'Transpose'):\n",
    "                 \n",
    "        super().__init__()    \n",
    "        \n",
    "        self.last_dim = last_dim\n",
    "        self.conv_dims = conv_dims\n",
    "    \n",
    "        ful_cn_nodes = ful_cn_nodes_decoder\n",
    "        layer_fc = [nn.Linear(ful_cn_nodes[i],ful_cn_nodes[i+1]) for i in range(len(ful_cn_nodes)-1)  ]\n",
    "        self.layer_fc = nn.ModuleList(layer_fc)     \n",
    "        \n",
    "        \n",
    "        conv_nr = conv_nr_decoder\n",
    "        self.conv_nr = conv_nr\n",
    "        conv_sizes = conv_sizes_decoder\n",
    "        \n",
    "        if type(conv_strides_decoder) == int:\n",
    "            conv_strides_decoder = [conv_strides_decoder for _ in conv_sizes]\n",
    "            \n",
    "        padding = 0\n",
    "        \n",
    "        if conv_type == 'Transpose':\n",
    "            convFunction = torch.nn.ConvTranspose2d\n",
    "        else:\n",
    "            convFunction = torch.nn.Conv2d\n",
    "        \n",
    "        layer_con = [convFunction(\n",
    "            in_channels=conv_nr[i],      \n",
    "            out_channels = conv_nr[i+1],\n",
    "            kernel_size = conv_sizes[i],\n",
    "            stride = conv_strides_decoder[i],\n",
    "            padding = padding) for i in range(len(conv_sizes))]\n",
    "        \n",
    "        self.layer_con = nn.ModuleList(layer_con)\n",
    "        \n",
    "        \n",
    "        self.upsample = False\n",
    "        if len(pooling_dims)> 0:\n",
    "            self.upsample = True\n",
    "            layer_up = [torch.nn.Upsample(size=tuple(pd), mode = pooling_mode ) for pd in pooling_dims]\n",
    "            self.layer_up = nn.ModuleList(layer_up)  \n",
    "            \n",
    "        else: self.layer_up = [[] for _ in self.layer_con]\n",
    "        \n",
    "        if dropout_decoder > 0 :\n",
    "            self.use_dropout = True\n",
    "            layer_dropout = [nn.Dropout(p=dropout_decoder) for _ in zip(conv_sizes)]\n",
    "            self.layer_dropout = nn.ModuleList(layer_dropout)\n",
    "            \n",
    "        else:\n",
    "            self.use_dropout = False\n",
    "            self.layer_dropout = [[] for _ in self.layer_con]\n",
    "        \n",
    "        \n",
    "        if activations == 'mish':\n",
    "            self.activations_con = [F.mish for _ in conv_sizes]\n",
    "            self.activations_fc = [F.mish for _ in ful_cn_nodes[:-1]]\n",
    "            activation_strings = ['mish' for _ in range(len(conv_sizes)+len(ful_cn_nodes)-1)]\n",
    "            \n",
    "            \n",
    "        if activations == 'relu':\n",
    "            self.activations_con = [F.relu for _ in conv_sizes]\n",
    "            self.activations_fc = [F.relu for _ in ful_cn_nodes[:-1]]\n",
    "            activation_strings = ['relu' for _ in range(len(conv_sizes)+len(ful_cn_nodes)-1)]\n",
    "            \n",
    "\n",
    "        \n",
    "        self.decoder_args = {\n",
    "            'convolution layer decoder': conv_nr,\n",
    "            'filter sizes decoder':conv_sizes,\n",
    "            'fully_connected decoder': ful_cn_nodes,\n",
    "            'encoder_activations decoder': activation_strings,\n",
    "            }\n",
    "\n",
    "     def forward(self, x):\n",
    "        batch, _ = x.shape\n",
    "        \n",
    "        for activations, layer in zip(self.activations_fc, self.layer_fc):\n",
    "            x = activations(layer(x))\n",
    "        \n",
    "        \n",
    "        x = x.view(batch,self.conv_nr[0],self.last_dim[0], self.last_dim[1]) #-1 is imdim\n",
    "        \n",
    "        for activations, layer, upsam,cs,dropout in zip(self.activations_con, self.layer_con, self.layer_up, self.conv_dims, self.layer_dropout):\n",
    "            if self.upsample:\n",
    "                x = upsam(x)\n",
    "             \n",
    "            if self.use_dropout:\n",
    "                x = dropout(x)    \n",
    "                \n",
    "            x = activations(layer(x, output_size = cs)) \n",
    "\n",
    "       # x = x.view(batch, -1)\n",
    "        #assert x.shape[0] == 3, 'output dim has to be batch, imdim0,imdim1'\n",
    "        torch.squeeze(x,1)\n",
    "        return x      \n",
    "        \n",
    "        \n",
    "     def load(self, path = 'testpath'):\n",
    "        self.decoder.load_state_dict(torch.load(path +'_decoder',map_location=torch.device(self.device)))\n",
    "        \n",
    "def get_model(id_string, rootpath,device):\n",
    "    file  = open(rootpath+id_string+'/paramdict.pkl','rb')\n",
    "    model_dict = pickle.load(file)\n",
    "    modeltype = Conv2d_autoencoder\n",
    "    kwargs = model_dict['kwargs']\n",
    "    kwargs.pop('__class__',None)\n",
    "    kwargs.pop('self',None)\n",
    "    if device == 'cpu':\n",
    "        kwargs['device'] = 'cpu'\n",
    "    model = modeltype(**kwargs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "class Conv2d_autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_dim= (640,2360), \n",
    "                 device = 'cpu',\n",
    "                 train = True,\n",
    "                 activations='mish', \n",
    "                 conv_sizes_encoder = [5,5,5], \n",
    "                 conv_nr_encoder = [1,8,16,32], \n",
    "                 conv_strides_encoder = 1,\n",
    "                 pooling_kernel_size = [],\n",
    "                 pooling_stride = [],       \n",
    "                 interpolation_mode ='nearest',\n",
    "                 ful_cn_nodes_encoder = [-1,500,24],\n",
    "                 dropout_encoder = -1,\n",
    "                 dropout_decoder = -1,\n",
    "                 batch_norm = False,\n",
    "                 conv_type_decoder = 'Transpose'):\n",
    "                 \n",
    "        super().__init__()\n",
    "        self.kwargs = locals()\n",
    "        self.kwargs.pop('__class__',None)\n",
    "        self.kwargs.pop('self',None)\n",
    "        self.latent_dims = int(ful_cn_nodes_encoder[-1]/2)\n",
    "        self.device = device\n",
    "        \n",
    "       # assert len(pooling_kernel_size)<=0: 'pooling is not implemented yet, as upsampling is not trivial'\n",
    "        #gib die dem encoder\n",
    "        \n",
    "        self.encoder = Conv2d_encoder(\n",
    "                 input_dim= input_dim, \n",
    "                 train = train,\n",
    "                 device = device,\n",
    "                 activations=activations, \n",
    "                 conv_sizes_encoder = conv_sizes_encoder, \n",
    "                 conv_nr_encoder = conv_nr_encoder, \n",
    "                 conv_strides_encoder = conv_strides_encoder,\n",
    "                 pooling_kernel_size = pooling_kernel_size,\n",
    "                 pooling_stride = pooling_stride,             \n",
    "                 ful_cn_nodes_encoder = ful_cn_nodes_encoder,\n",
    "                 dropout_encoder= dropout_encoder,\n",
    "                 batch_norm = batch_norm)\n",
    "        \n",
    "        # bilde die Argumente für den Decoder (inklusive last dim)\n",
    "        last_dim_encoder = self.encoder.last_dim\n",
    "        if type(conv_sizes_encoder) == list :\n",
    "            conv_sizes_decoder = conv_sizes_encoder[::-1]\n",
    "        else:\n",
    "            conv_sizes_decoder = conv_sizes_encoder\n",
    "        if type(conv_nr_encoder) == list :\n",
    "            conv_nr_decoder =  conv_nr_encoder[::-1]\n",
    "        else: \n",
    "            conv_nr_decoder =  conv_nr_encoder\n",
    "        if type(conv_strides_encoder) == list :\n",
    "            conv_strides_decoder = conv_strides_encoder[::-1]\n",
    "        else:\n",
    "            conv_strides_decoder = conv_strides_encoder\n",
    "        \n",
    "        \n",
    "        \n",
    "        ful_cn_nodes_decoder = ful_cn_nodes_encoder[::-1]\n",
    "        ful_cn_nodes_decoder[0] = int(ful_cn_nodes_decoder[0]/2)\n",
    "        ful_cn_nodes_decoder[-1] = int(self.encoder.last_dim[0]*self.encoder.last_dim[1]*conv_nr_encoder[-1])\n",
    "        \n",
    "        pooling_dims = self.encoder.pooling_dims[::-1] #may cause problems due to rounding problems\n",
    "        conv_dims = self.encoder.conv_dims[::-1]    \n",
    "        \n",
    "        self.decoder = Conv2d_decoder(\n",
    "                 last_dim = last_dim_encoder, #2d\n",
    "                 activations=activations, \n",
    "                 conv_sizes_decoder = conv_sizes_decoder, \n",
    "                 conv_nr_decoder = conv_nr_decoder, \n",
    "                 conv_strides_decoder = conv_strides_decoder,          \n",
    "                 pooling_dims = pooling_dims,\n",
    "                 conv_dims = conv_dims,\n",
    "                 pooling_mode = interpolation_mode,\n",
    "                 ful_cn_nodes_decoder = ful_cn_nodes_decoder,\n",
    "                 dropout_decoder = dropout_decoder,\n",
    "                 conv_type = conv_type_decoder)\n",
    "         \n",
    "        self.decoder = self.decoder.to(device)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "        \n",
    "    def load(self, path = 'testpath'):\n",
    "        self.decoder.load_state_dict(torch.load(path +'_decoder',map_location=torch.device(self.device)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(rand_id, rootpath='./model/', epoch = -1,device='cpu'): #medelnam is folder name (sim/meas)\n",
    "    if epoch <0:\n",
    "        saveepochs = [int(savestring.split('_')[-2]) for savestring in glob(rootpath+str(rand_id)+'/'+'*_decoder')]\n",
    "        epoch = max(saveepochs)\n",
    "        \n",
    "    savepoint = rootpath+'{:s}/{:s}_{:d}'.format(rand_id,rand_id,epoch)\n",
    "    savedir = rootpath+str(rand_id)+'/'\n",
    "    \n",
    "    if os.path.exists(savedir+'paramdict.pkl'):\n",
    "        model = get_model(rand_id, rootpath,device=device)\n",
    "        model.load(savepoint)\n",
    "    else:\n",
    "        print('No saved model parameters found')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sort_by_generation(x):\n",
    "    _, generation, _ = Path(x).stem.split('_')\n",
    "    return int(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir =  './model/'\n",
    "#config_files = sorted(glob(f'{config_dir}/*/*.json'))\n",
    "config_files = [os.path.join(config_dir,'pc{:03d}'.format(i),'pc{:03d}.json'.format(i)) for i in range(142,144)]\n",
    "\n",
    "config_files = [glob(config_dir + 'sim/*.json')[0],glob(config_dir + 'meas/*.json')[0]]\n",
    "\n",
    "model_names = [\n",
    "    'sim',\n",
    "    'meas'\n",
    "]\n",
    "model_infos = [\n",
    "    AttrDict(json.load(open(c))).info\n",
    "    for c in config_files\n",
    "]\n",
    "model_decoders = [\n",
    "    sorted(glob(f'{config_dir}/{n}/{n}_*_decoder'), key=sort_by_generation)\n",
    "    for n in model_names\n",
    "]\n",
    "model_z_dims = [\n",
    "    AttrDict(json.load(open(c))).fit.model_param.ful_cn_nodes_encoder[-1] // 2\n",
    "    for c in config_files\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    f\"{model_names[idx]}\": {\n",
    "        'config_file': config_files[idx],\n",
    "        'model_name': model_names[idx],\n",
    "        'model_info': model_infos[idx],\n",
    "        'model_z_dim': model_z_dims[idx],\n",
    "        'model_decoder': model_decoders[idx],\n",
    "    }\n",
    "    for idx in range(len(config_files))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_model(model_dict):\n",
    "    model_dict = AttrDict(model_dict)\n",
    "\n",
    "    model = get_trained_model(model_dict.model_name, f'{config_dir}/')\n",
    "    decoder = model.decoder\n",
    "    z_dim = decoder.layer_fc[0].in_features\n",
    "    y_dim = decoder.layer_up[1].size\n",
    "    assert z_dim == model_dict.model_z_dim\n",
    "    \n",
    "    return decoder, z_dim, y_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_slider_change(change):\n",
    "    values = [alpha.value for alpha in z_sliders]\n",
    "    z = torch.tensor(values)[None, :]\n",
    "    try:\n",
    "        y = decoder(z).detach().cpu()\n",
    "    except Exception as e:\n",
    "        caption.value = (str(e))\n",
    "        return\n",
    "    y = y.reshape(y.shape[-2:])\n",
    "    if y.shape[-1] == 200:\n",
    "        y = np.rot90(y)\n",
    "    im.set_data(y)\n",
    "    #caption.value = (y.shape)\n",
    "    \n",
    "    fig.canvas.draw_idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_slider_change2(change):\n",
    "    values = [alpha.value for alpha in z_sliders2]\n",
    "    z = torch.tensor(values)[None, :]\n",
    "    try:\n",
    "        y = decoder2(z).detach().cpu()\n",
    "    except Exception as e:\n",
    "        caption.value = (str(e))\n",
    "        return\n",
    "    y = y.reshape(y.shape[-2:])\n",
    "    if y.shape[-1] == 200:\n",
    "        y = np.rot90(y)\n",
    "    im2.set_data(y)\n",
    "    #caption.value = (y.shape)\n",
    "    \n",
    "    if np.array_equal(values,[2.5]*10):\n",
    "        im2.set_data(imageio.imread('./easteregg/importantImage2.png'))\n",
    "    \n",
    "    fig2.canvas.draw_idle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trained on simulated  data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|||\n",
    "|--|--|\n",
    "|not used| z0, z3, z4|\n",
    "|energy at start and end of bunch|z1, z8|\n",
    "|lasing|z2|\n",
    "|energy of bunch|z6|\n",
    "|duration of lasing|z7|\n",
    "|temporal profile of electron bunch|z5, z9|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45ddf35f98a42bcac5263320bb982a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "'turbo' is not a valid value for name; supported values are 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b78dc1ef7a9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'turbo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5620\u001b[0m             \u001b[0maspect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image.aspect'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5621\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_aspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5622\u001b[0;31m         im = mimage.AxesImage(self, cmap, norm, interpolation, origin, extent,\n\u001b[0m\u001b[1;32m   5623\u001b[0m                               \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ax, cmap, norm, interpolation, origin, extent, filternorm, filterrad, resample, **kwargs)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    891\u001b[0m             \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ax, cmap, norm, interpolation, origin, filternorm, filterrad, resample, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m                  ):\n\u001b[1;32m    247\u001b[0m         \u001b[0mmartist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScalarMappable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mouseover\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morigin\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/cm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, norm, cmap)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m#: The Colormap instance of this ScalarMappable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;31m#: The last colorbar associated with this ScalarMappable. May be None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/cm.py\u001b[0m in \u001b[0;36mget_cmap\u001b[0;34m(name, lut)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColormap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_in_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmap_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlut\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcmap_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_check_in_list\u001b[0;34m(_values, **kwargs)\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2144\u001b[0m                 \u001b[0;34m\"{!r} is not a valid value for {}; supported values are {}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m                 .format(v, k, ', '.join(map(repr, values))))\n",
      "\u001b[0;31mValueError\u001b[0m: 'turbo' is not a valid value for name; supported values are 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r'"
     ]
    }
   ],
   "source": [
    "decoder, z_dim, y_dim = select_model(model_dict['sim'])\n",
    "z_sliders = [\n",
    "    widgets.FloatSlider(min=-2.5, max=2.5, step=1e-3, description=f'$z_{{{i}}}$', orientation='vertical')\n",
    "    for i in range(z_dim)\n",
    "]\n",
    "for widget in z_sliders:\n",
    "    widget.observe(handle_slider_change, names='value')\n",
    "\n",
    "model_name = 'sim'\n",
    "\n",
    "plt.close('all')\n",
    "fig = plt.figure(f\"Neural reconstruction using decoder part of model '{model_name}'\", dpi=100, constrained_layout=True) #, figsize=y_dim)\n",
    "fig.set_facecolor(color_bg)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.axis('off')\n",
    "im = ax.imshow(np.random.random(y_dim), cmap='turbo')\n",
    "im.set_data(np.zeros(y_dim))\n",
    "\n",
    "ui = widgets.HBox(z_sliders)\n",
    "caption = widgets.Label(value='')\n",
    "display(ui, caption)\n",
    "print('')\n",
    "handle_slider_change(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trained on real world  data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|||\n",
    "|--|--|\n",
    "|lasing| z9|\n",
    "|len of electron bunch/ lasing position| z1, z7|\n",
    "|temporal profile/ chirp| z4,z6|\n",
    "|bunching due to accelerator| z0, z2, z3, z5 , z8|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder2, z_dim2, y_dim2 = select_model(model_dict['meas'])\n",
    "z_sliders2 = [\n",
    "    widgets.FloatSlider(min=-2.5, max=2.5, step=1e-3, description=f'$z_{{{i}}}$', orientation='vertical')\n",
    "    for i in range(z_dim2)\n",
    "]\n",
    "for widget in z_sliders2:\n",
    "    widget.observe(handle_slider_change2, names='value')\n",
    "\n",
    "model_name = 'meas'\n",
    "\n",
    "plt.close(f\"Neural reconstruction using decoder part of model '{model_name}'\")\n",
    "fig2 = plt.figure(f\"Neural reconstruction using decoder part of model '{model_name}'\", dpi=100, constrained_layout=True) #, figsize=y_dim)\n",
    "fig2.set_facecolor(color_bg)\n",
    "ax2 = fig2.add_subplot(1, 1, 1)\n",
    "ax2.axis('off')\n",
    "im2 = ax2.imshow(np.random.random(y_dim2), cmap='turbo')\n",
    "im2.set_data(np.zeros(y_dim2))\n",
    "\n",
    "ui2 = widgets.HBox(z_sliders2)\n",
    "caption2 = widgets.Label(value='')\n",
    "display(ui2, caption2)\n",
    "print('')\n",
    "handle_slider_change2(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
